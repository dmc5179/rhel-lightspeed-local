# Save the output of this file and use kubectl create -f to import
# it into Kubernetes.
#
# Created with podman-5.4.0
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  annotations:
    volume.podman.io/driver: local
  creationTimestamp: "2025-09-02T15:28:28Z"
  name: llamacpp-models
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
status: {}
---
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: "2025-09-02T15:28:28Z"
  labels:
    app: rhel-lightspeed
  name: rhel-lightspeed
spec:
  ports:
  - name: "8000"
    nodePort: 32611
    port: 8000
    targetPort: 8000
  - name: "8888"
    nodePort: 30035
    port: 8888
    targetPort: 8888
  selector:
    app: rhel-lightspeed
  type: NodePort
---
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: "2025-09-02T15:28:28Z"
  labels:
    app: rhel-lightspeed
  name: rhel-lightspeed-deployment
spec:
  selector:
    matchLabels:
      app: rhel-lightspeed
  template:
    metadata:
      annotations:
        io.kubernetes.cri-o.SandboxID/llamacpp-model: 7b6e3789f97cd64df8c586fbc7a6e41b734420e39f75875debb9ea57e5aa0db4
        io.kubernetes.cri-o.SandboxID/pgvector: 7b6e3789f97cd64df8c586fbc7a6e41b734420e39f75875debb9ea57e5aa0db4
        io.kubernetes.cri-o.SandboxID/rlsapi: 7b6e3789f97cd64df8c586fbc7a6e41b734420e39f75875debb9ea57e5aa0db4
      creationTimestamp: "2025-09-02T15:28:28Z"
      labels:
        app: rhel-lightspeed
      name: rhel-lightspeed
    spec:
      containers:
      - env:
        - name: POSTGRES_PASSWORD
          value: postgres
        - name: POSTGRES_HOST
          value: 127.0.0.1
        - name: POSTGRES_PORT
          value: "5432"
        - name: PGVECTOR_DBNAME
          value: ragdb
        - name: POSTGRES_USER
          value: postgres
        image: quay.io/redhat-user-workloads/rhel-lightspeed-tenant/rag-database:latest
        name: pgvector
        ports:
        - containerPort: 8000
        - containerPort: 8888
        securityContext:
          seLinuxOptions:
            type: spc_t
        volumeMounts:
        - mountPath: /dev/shm
          name: tmp-0
      - command:
        - ramalama
        - --store
        - /models
        - --debug
        - serve
        - --port
        - "8888"
        - --host
        - 0.0.0.0
        - file:///models/Phi-4-mini-instruct-Q4_K_M.gguf
        env:
        - name: CUDA_VISIBLE_DEVICES
          value: "0"
        - name: HF_HOME
          value: /models/.cache/huggingface
        image: quay.io/ramalama/cuda:latest
        name: llamacpp-model
        securityContext:
          seLinuxOptions:
            type: spc_t
        volumeMounts:
        - mountPath: /dev/shm
          name: tmp-0
        - mountPath: /models
          name: llamacpp-models-pvc
      - env:
        - name: HF_HOME
          value: /tmp/huggingface
        - name: EMBED_CHUNK_OVERLAP
          value: "15"
        - name: LLM_TIMEOUT_SECONDS
          value: "120"
        - name: WORKFLOW_TIMEOUT_SECONDS
          value: "120"
        - name: ENABLE_AUTH
          value: "false"
        - name: DB_PASSWORD
          value: postgres
        - name: EMBED_CHUNK_SIZE
          value: "275"
        - name: OPENAI_MODEL
          value: /models/Phi-4-mini-instruct-Q4_K_M.gguf
        - name: OPENAI_API_BASE
          value: http://0.0.0.0:8888/v1
        - name: EMBED_MODEL
          value: ibm-granite/granite-embedding-30m-english
        - name: EMBED_DIMENSION
          value: "384"
        - name: REQUEST_TIMEOUT_ERROR
          value: "120"
        - name: EMBED_BATCH_SIZE
          value: "50"
        - name: LLM_PROVIDER
          value: openai
        image: quay.io/redhat-user-workloads/rhel-lightspeed-tenant/rlsapi/rlsapi:main
        name: rlsapi
        securityContext:
          seLinuxOptions:
            type: spc_t
      volumes:
      - name: llamacpp-models-pvc
        persistentVolumeClaim:
          claimName: llamacpp-models
      - emptyDir:
          medium: Memory
        name: tmp-0
